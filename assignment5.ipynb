{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KNN:\n",
    "    def __init__(self, k=3, distance_metric='euclidean'):\n",
    "        self.k = k\n",
    "        self.distance_metric = distance_metric\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.X_train = X\n",
    "        self.y_train = y\n",
    "\n",
    "    def compute_distance(self, X1, X2):\n",
    "        if self.distance_metric == 'euclidean':\n",
    "            distances = np.sqrt(np.sum((X1 - X2) ** 2, axis=1))\n",
    "        elif self.distance_metric == 'manhattan':\n",
    "            distances = np.sum(np.abs(X1 - X2), axis=1)\n",
    "        else:\n",
    "            raise ValueError(\"Unsupported distance metric\")\n",
    "        return distances\n",
    "\n",
    "    def predict(self, X):\n",
    "        \n",
    "        y_pred = []\n",
    "        for x_test in X:\n",
    "            distances = self.compute_distance(self.X_train, x_test)\n",
    "            k_indices = np.argsort(distances)[:self.k]\n",
    "            k_nearest_labels = self.y_train[k_indices]\n",
    "            prob = np.mean(k_nearest_labels)\n",
    "            y_pred.append(prob)\n",
    "        return np.array(y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(train_path, test_path):\n",
    "    \n",
    "    train_data = pd.read_csv(train_path)\n",
    "    test_data = pd.read_csv(test_path)\n",
    "\n",
    "    \n",
    "    train_data = train_data.drop(['CustomerId', 'Surname'], axis=1)\n",
    "    test_data = test_data.drop(['CustomerId', 'Surname'], axis=1)\n",
    "\n",
    "    \n",
    "    test_data['Exited'] = -1  \n",
    "\n",
    "    \n",
    "    combined_data = pd.concat([train_data, test_data], ignore_index=True)\n",
    "\n",
    "    \n",
    "    combined_data = pd.get_dummies(combined_data, columns=['Geography', 'Gender'], drop_first=True)\n",
    "\n",
    "    \n",
    "    train_data = combined_data[combined_data['Exited'] != -1]\n",
    "    test_data = combined_data[combined_data['Exited'] == -1].drop('Exited', axis=1)\n",
    "\n",
    "   \n",
    "    y = train_data['Exited'].values\n",
    "    X = train_data.drop('Exited', axis=1).values\n",
    "    X_test = test_data.values\n",
    "\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    X = scaler.fit_transform(X)\n",
    "    X_test = scaler.transform(X_test)\n",
    "\n",
    "    return X, y, X_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validate(X, y, knn, n_splits=5):\n",
    "    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "    auc_scores = []\n",
    "\n",
    "    for train_index, val_index in skf.split(X, y):\n",
    "        X_train_cv, X_val_cv = X[train_index], X[val_index]\n",
    "        y_train_cv, y_val_cv = y[train_index], y[val_index]\n",
    "\n",
    "        knn.fit(X_train_cv, y_train_cv)\n",
    "        y_pred = knn.predict(X_val_cv)\n",
    "        auc = roc_auc_score(y_val_cv, y_pred)\n",
    "        auc_scores.append(auc)\n",
    "\n",
    "    return auc_scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hyperparameter_tuning(X, y):\n",
    "    k_values = range(1, 11)  \n",
    "    distance_metrics = ['euclidean', 'manhattan']\n",
    "    best_auc = 0\n",
    "    best_params = {}\n",
    "\n",
    "    for k in k_values:\n",
    "        for metric in distance_metrics:\n",
    "            knn = KNN(k=k, distance_metric=metric)\n",
    "            cv_scores = cross_validate(X, y, knn, n_splits=5)\n",
    "            mean_auc = np.mean(cv_scores)\n",
    "            print(f\"k={k}, metric={metric}, AUC={mean_auc:.4f}\")\n",
    "            if mean_auc > best_auc:\n",
    "                best_auc = mean_auc\n",
    "                best_params = {'k': k, 'distance_metric': metric}\n",
    "    print(f\"\\nBest parameters: k={best_params['k']}, metric={best_params['distance_metric']}, AUC={best_auc:.4f}\")\n",
    "    return best_params\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting hyperparameter tuning...\n",
      "\n",
      "k=1, metric=euclidean, AUC=0.7492\n",
      "k=1, metric=manhattan, AUC=0.7456\n",
      "k=2, metric=euclidean, AUC=0.8113\n",
      "k=2, metric=manhattan, AUC=0.8123\n",
      "k=3, metric=euclidean, AUC=0.8380\n",
      "k=3, metric=manhattan, AUC=0.8390\n",
      "k=4, metric=euclidean, AUC=0.8561\n",
      "k=4, metric=manhattan, AUC=0.8561\n",
      "k=5, metric=euclidean, AUC=0.8668\n",
      "k=5, metric=manhattan, AUC=0.8663\n",
      "k=6, metric=euclidean, AUC=0.8731\n",
      "k=6, metric=manhattan, AUC=0.8752\n",
      "k=7, metric=euclidean, AUC=0.8789\n",
      "k=7, metric=manhattan, AUC=0.8788\n",
      "k=8, metric=euclidean, AUC=0.8827\n",
      "k=8, metric=manhattan, AUC=0.8833\n",
      "k=9, metric=euclidean, AUC=0.8863\n",
      "k=9, metric=manhattan, AUC=0.8882\n",
      "k=10, metric=euclidean, AUC=0.8899\n",
      "k=10, metric=manhattan, AUC=0.8903\n",
      "\n",
      "Best parameters: k=10, metric=manhattan, AUC=0.8903\n",
      "\n",
      "Training the final model...\n",
      "Making predictions on the test set...\n",
      "Submission file 'submissions.csv' has been created.\n"
     ]
    }
   ],
   "source": [
    "# Main script\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    X, y, X_test = preprocess_data('train.csv', 'test.csv')\n",
    "\n",
    "    \n",
    "    print(\"Starting hyperparameter tuning...\\n\")\n",
    "    best_params = hyperparameter_tuning(X, y)\n",
    "\n",
    "    \n",
    "    print(\"\\nTraining the final model...\")\n",
    "    knn = KNN(k=best_params['k'], distance_metric=best_params['distance_metric'])\n",
    "    knn.fit(X, y)\n",
    "\n",
    "    \n",
    "    print(\"Making predictions on the test set...\")\n",
    "    test_predictions = knn.predict(X_test)\n",
    "\n",
    "    \n",
    "    test_predictions = np.clip(test_predictions, 0, 1)\n",
    "\n",
    "    \n",
    "    test_ids = pd.read_csv('test.csv')['id']\n",
    "\n",
    "    submission = pd.DataFrame({'id': test_ids, 'Exited': test_predictions})\n",
    "    submission.to_csv('submissions.csv', index=False)\n",
    "    print(\"Submission file 'submissions.csv' has been created.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
